# AI Model Configuration - Edit to enable features
# Models are DISABLED by default - enable only what you need

# Worker Pool (for high-performance processing)
worker_pool:
  enabled: false  # Enable for parallel processing of multiple requests
  num_workers: 2  # Number of worker processes (more = handle more concurrent requests)
  devices: ["auto"]  # Auto-detect all GPUs, or specify: ["cuda:0", "cuda:1"], or ["cpu"]  
  require_gpu: false  # Work on CPU-only systems
  
  # Workers are distributed across available devices:
  # - 2 workers + 1 GPU = both workers share the GPU memory
  # - 4 workers + 2 GPUs = 2 workers per GPU
  # - 4 workers + CPU = all workers use CPU cores

# Example Models (all disabled by default)
models:
  
  # Small, fast embedding model (good for development/testing)
  small_embeddings:
    type: "embedding"
    name: "sentence-transformers/all-MiniLM-L6-v2"
    device: "cpu"
    dimension: 384
    enabled: false  # User enables this
    
  # Large, high-quality embedding model (production)
  large_embeddings:
    type: "embedding"
    name: "mixedbread-ai/mxbai-embed-large-v1"
    device: "auto"
    dimension: 1024
    enabled: false  # User enables this
    
  # Text summarization model
  summarizer:
    type: "text2text"
    name: "google/flan-t5-small"  # Start with small version
    device: "cpu"
    enabled: false  # User enables this

# Custom models - users add their own
# custom_model:
#   type: "embedding"
#   name: "your/model-name"
#   device: "auto" 
#   enabled: false

# Performance settings
embedding_cache:
  enabled: true
  max_cache_size: 10000
  ttl_seconds: 3600